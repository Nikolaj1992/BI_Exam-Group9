{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40957204-781e-4320-8ff5-78a8ec3de700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c2011b-9456-48ec-853a-02c1f46887ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install poppler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3a6877-60f7-46f2-abca-13736ba7efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189081c8-86d7-44da-a5dd-1f20221085ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and parcing web pages\n",
    "from langchain_community.document_loaders import SeleniumURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c69b46-284c-45ad-9564-673aa1f1ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and parcing multimodal pdf\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.utils.constants import PartitionStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cd42b8-7944-4554-9a57-60ee657dbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for help of open-source LLMs\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff84bed7-b481-4be0-ac04-27151e8726c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text pre-processing\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1839ab48-16a3-4f1b-a977-3a028a60579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46a71dd-dcca-4c6b-b021-448405525be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull gemma3:12b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fdbd23-7851-40a7-b959-29d5e3fc41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull llama3.2:3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3261db80-453e-4691-a676-23ad25472164",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model = \"gemma3:12b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467c693b-f59b-4217-9966-961f51caec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2:3b\")\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049d5546-d6aa-4d6a-b4fb-f87de7a87df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load page\n",
    "def load_web_page(url):\n",
    "    loader = SeleniumURLLoader(urls=[url])\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c60958-cecb-48e0-8c9b-e79187604478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the page text\n",
    "def split_web_text(docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    data = text_splitter.split_documents(docs)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5be0ec-5822-465c-bbcd-f824518e3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_web_docs(docs):\n",
    "    vector_store.add_documents(docs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38312c0-59ff-40cf-9c84-7d7066f1fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(query):\n",
    "    return vector_store.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace29bc5-84da-4054-8db4-c760a54d9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, documents):\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | llm\n",
    "    return chain.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f76f93a-1e1a-4e66-9747-602189794715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A template for the dialoque\n",
    "template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99f8977d-ea08-47b5-a5fd-919d74ad2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://escinsight.com/2023/04/06/deeper-look-eurovisions-running-order/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18489a29-80e3-42f6-a2cf-29c8821bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a web page\n",
    "doc = load_web_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64898e88-ab4f-4b48-bf64-f9f0987c687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text in chunks\n",
    "text = split_web_text(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b78b1725-cf74-44cd-be0e-a2386f3d3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the chunks and store them in vector db\n",
    "store_web_docs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0bc112b-e578-45e7-b475-455b2959c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what running order is the best?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "254be918-70cd-45d9-ac10-a5ebe1118876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the user's question to the vector db for retrieving relevant context\n",
    "retrieved = retrieve_docs(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c2b3441-e1d3-4846-b600-72cab391d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='424b6770-0688-4f10-8256-8eb0720be051', metadata={'source': 'https://escinsight.com/2023/04/06/deeper-look-eurovisions-running-order/', 'title': 'ESC Insight | A Deeper Look At Eurovision’s Running Order', 'description': 'No description found.', 'language': 'No language found.', 'start_index': 10118}, page_content='Finally, we have the bottom left in light orange, which is where we find acts that did better in the final among both jurors and televoters. The position that televoters reward the most is 25th, which is usually the penultimate slot (although in 2022 it was the final slot, on account of the contest having previously been won by Italy, one of the Big Five). The slot just before this – 24th – is the position that jurors reward the most. Almost all of these slots can be found towards the end of their respective halves: this isn’t true for 5th and 15th, but these only just squeeze into the category.\\n\\nSo Where Do I Want To Sing?'),\n",
       " Document(id='fa9b6313-9985-43c6-a451-a043a5e3c25a', metadata={'source': 'https://escinsight.com/2023/04/06/deeper-look-eurovisions-running-order/', 'title': 'ESC Insight | A Deeper Look At Eurovision’s Running Order', 'description': 'No description found.', 'language': 'No language found.', 'start_index': 6532}, page_content='What About Those Not Singing Last?\\n\\nThere are (usually) another 25 positions we’re interested in. Is performing second really a curse? Or could it be that a producer looking to entertain and engage the audience is unlikely to put a massively attractive act on second? In Melodifestivalen, Christer Bjorkman always liked to start the show with a bang, and the second song would bring the tempo down. The same could be true for the Eurovision Song Contest production team as well.\\n\\nWe can answer this question by applying the technique we’ve just used to every single running order position. We start with every act that has performed in both a semi-final and a grand final since 2014. We then look at their change in rankings among the other acts that qualified from their semi-final among the juries and televoters that voted on them both times and look at the average for each group. Finally, we take the average changes for each position.'),\n",
       " Document(id='9863b5af-a3c4-4e94-8639-0653d161e1ae', metadata={'source': 'https://escinsight.com/2023/04/06/deeper-look-eurovisions-running-order/', 'title': 'ESC Insight | A Deeper Look At Eurovision’s Running Order', 'description': 'No description found.', 'language': 'No language found.', 'start_index': 9150}, page_content='The top left, in green, is the opposite: positions that televoters preferred in the final but that juries preferred in the semi. We can see 26th (or last) position here again, which should come as no surprise, but what’s interesting is that it’s very close to the 13th position, which is usually the final slot among the acts that have been allocated to the first half. The songs in 13th position are a real mix of styles: it’s hard to make many comparisons between ‘Better Love’, ‘My Friend’, and ‘Sound of Silence’.\\n\\nHaving won the jury vote overall, we might not think of Dami Im as an act who suffered among the jurors in the Grand Final. But she dropped in the rankings among seven juries, and didn’t increase in any. Maybe if she’d been in a different position in the running order in the Grand Final, we’d have had a different winner? Either way, acts performing in 13th or 26th drop by a full half ranking among their fellow semi-final qualifiers on average.'),\n",
       " Document(id='bdf87825-2ebc-4000-82bf-ea42f977c209', metadata={'source': 'https://escinsight.com/2023/04/06/deeper-look-eurovisions-running-order/', 'title': 'ESC Insight | A Deeper Look At Eurovision’s Running Order', 'description': 'No description found.', 'language': 'No language found.', 'start_index': 3045}, page_content='The EBU has published detailed voting results capturing televote and jury votes from the Semi Finals and Grand Finals since 2014. In those eight Contests, one of the Big Five has performed last five times; the UK in 2014, Italy in 2015 and 2018, France in 2017, and Spain in 2019. That leaves just three performances where we can draw this comparison: Armenia in 2016, San Marino in 2021, and Estonia in 2022.\\n\\nMeasuring Change')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cdef3e2-0584-4436-ba62-63ef2c280dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = answer_question(question, retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17bceda9-a857-438c-b160-9a937c03d753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There\\'s no definitively \"best\" running order position. However, positions 13th and 26th (last) tend to see acts drop in rankings among their fellow semi-final qualifiers. The 24th position is favored by jurors, while the 25th position is favored by televoters.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca07a041-67c6-4818-bc36-cfde584f35d3",
   "metadata": {},
   "source": [
    "### Naives Bayes Classification \n",
    "We are trying to make a Naives Bayes model, that can predict top10, \n",
    "with features final_draw_position, final_televote_points, final_jury_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81b375-259e-410c-b34e-7ffdaa142ef1",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75480705-e640-40b7-b2cd-f633dff123ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfdd93-e812-43cd-858b-788a0fd42727",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3bbbd-7f5b-4ec5-9a6d-8256ea6c3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/finalists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f63df-7599-4cd1-b200-d5c290fa4f70",
   "metadata": {},
   "source": [
    "#### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a0e38-5558-41ca-b4ff-9bd84f55ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bf8f5-ada2-4d7f-92ac-b205f1e3c128",
   "metadata": {},
   "source": [
    "Since we know what features we are gonna use in this model, we are only looking into those for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc51a9d-2308-43d3-a28a-2d0a8e20622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows where final_televote_points or final_jury_points is NaN\n",
    "df[df['final_televote_points'].isna() | df['final_jury_points'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026dbda-93d9-4237-b877-73d9f437c6d4",
   "metadata": {},
   "source": [
    "This visualize that the final_televotes_points and final_jury_points in 2013 is missing for all the countries, there for we decide to remove the whole year. Bonus info - we first ran the model with 2013 at got a F1-score on 0.91, but after we removed it we hit 0,96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c966d26-6c0e-4bd8-97e9-0ed033bb7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['year'] != 2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49680595-22a7-47f9-a82f-1952504f6a0c",
   "metadata": {},
   "source": [
    "#### Create Binary Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b091c76-9ea1-4977-9d43-6a73769d9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification: 1 = Top 10, 0 = Not Top 10\n",
    "df['top_10'] = df['final_place'].apply(lambda x: 1 if x <= 10 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fa1ad-c504-410d-963f-b9beb13ee427",
   "metadata": {},
   "source": [
    "#### Select Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650c95e-89ea-4f44-b8a8-26761799eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'final_draw_position',\n",
    "    'final_televote_points', 'final_jury_points'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['top_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e512d-cc0e-4484-9da5-7b442220ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5d14a-028a-46dc-97d3-7dea223b14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be85a4-9a8c-4f73-8992-955fe22d7b75",
   "metadata": {},
   "source": [
    "Since there is only 6 nans in both final_televote_points and final_jury_points we are filling them with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3ddb8-de09-479f-8a73-b903b4bfdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d4cc9-c6ba-4072-a0ef-1b277cbccf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe894e-b4dc-47e9-bcff-4ed1fcf9706d",
   "metadata": {},
   "source": [
    "shows alot of outlier. But since these points represent that some scores a high amount of points and some allmost nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90525d34-871e-4633-93a3-af3b3684486a",
   "metadata": {},
   "source": [
    "#### Splitting For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad2878-9abd-4acc-9d3e-ffd8f6b8fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed0f06-8179-44e3-8912-c7de3fb544ab",
   "metadata": {},
   "source": [
    "#### Train Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497c5a4-49b5-4b2b-bc7f-1d8b0e2ee981",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c0a60-0b75-42e6-86cf-22f8e2a27da4",
   "metadata": {},
   "source": [
    "#### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23374a3-de41-4721-b1ad-cc28f252ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy and report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('Images/NB_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea1ce3-9bd2-4867-8ede-cc968126182c",
   "metadata": {},
   "source": [
    "The F1 score of 0.96 indicates a high level of accuracy in Naive bayes classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21288071-6c23-45a0-a24e-2e70a7efecd8",
   "metadata": {},
   "source": [
    "#### Prediction on a New Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeccc81-ca15-4d85-87ac-592b96f5bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [[2, 20, 13]]  # draw, televote pts, jury pts\n",
    "sample_df = pd.DataFrame(sample, columns=features)\n",
    "prediction = model.predict(sample_df)\n",
    "print(\"Top 10 prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24504738-3d4d-4bc0-ae18-c176f8fd4c3c",
   "metadata": {},
   "source": [
    "#### Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237ec7e-bdf9-444c-b9a7-69d3f2de341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c0df4-aa78-41e4-93c1-ff8d14c25efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the model in a file\n",
    "model_file = 'Models/bayes.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12711b90-d25b-4647-8ee8-92721f42b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f72675-6c41-4301-a755-0ec67cd6e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
